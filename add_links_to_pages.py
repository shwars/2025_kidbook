import os
import re
from pymorphy2 import MorphAnalyzer

# –ü–∞–ø–∫–∞ —Å Markdown —Ñ–∞–π–ª–∞–º–∏
FOLDER_PATH = "pages"  # –£–∫–∞–∂–∏ —Å–≤–æ—é –ø–∞–ø–∫—É

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
morph = MorphAnalyzer()

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ
def read_markdown_files(folder):
    articles = {}
    for filename in os.listdir(folder):
        if filename.endswith(".md"):
            path = os.path.join(folder, filename)
            with open(path, "r", encoding="utf-8") as file:
                content = file.read()
                articles[filename] = content
    return articles

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤) –∏–∑ —Å—Ç–∞—Ç–µ–π
def extract_keywords(articles):
    keywords = {}
    for filename, content in articles.items():
        # –ë–µ—Ä–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏
        match = re.search(r"^# (.+)", content, re.MULTILINE)
        if match:
            keyword = match.group(1).strip().lower()  # –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ ‚Äî —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
            keywords[keyword] = filename
    return keywords

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Å–ª–æ–≤–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º pymorphy2
def lemmatize_word(word):
    parsed_word = morph.parse(word)[0]
    return parsed_word.normal_form

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–º–µ–Ω—ã –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –Ω–∞ —Å—Å—ã–ª–∫–∏ —Å —É—á–µ—Ç–æ–º –ø–∞–¥–µ–∂–µ–π –∏ –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –±—É–∫–≤
def insert_links(articles, keywords):
    updated_articles = {}
    for filename, content in articles.items():
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞, —Å–æ—Ö—Ä–∞–Ω—è—è –∏—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–∏–¥ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –∑–∞–º–µ–Ω—ã
        words = re.findall(r'\b\w+\b', content)
        for word in words:
            lemma_word = lemmatize_word(word.lower())  # –õ–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ–º —Å–ª–æ–≤–æ –¥–ª—è —É—á–µ—Ç–∞ –ø–∞–¥–µ–∂–µ–π –∏ —á–∏—Å–µ–ª
            if lemma_word in keywords and keywords[lemma_word] != filename:
                # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–∞–π–¥–µ–Ω–æ –≤ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞—Ö, –∑–∞–º–µ–Ω—è–µ–º –µ–≥–æ –Ω–∞ —Å—Å—ã–ª–∫—É
                content = re.sub(rf'\b{re.escape(word)}\b', f"[{word}]({keywords[lemma_word]})", content)
        updated_articles[filename] = content
    return updated_articles

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
def save_updated_files(folder, updated_articles):
    for filename, content in updated_articles.items():
        path = os.path.join(folder, filename)
        with open(path, "w", encoding="utf-8") as file:
            file.write(content)

# –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
articles = read_markdown_files(FOLDER_PATH)
keywords = extract_keywords(articles)
updated_articles = insert_links(articles, keywords)
save_updated_files(FOLDER_PATH, updated_articles)

print("üîó –°—Å—ã–ª–∫–∏ –≤—Å—Ç–∞–≤–ª–µ–Ω—ã –≤–æ –≤—Å–µ —Å—Ç–∞—Ç—å–∏!")
