
# Отчет по лабораторной работе
## по курсу "Искусственный интеллект"

### Студенты: 

| ФИО           | Роль в проекте                                                                                            | Оценка |
| ------------- | --------------------------------------------------------------------------------------------------------- | ------ |
| Адамов А.А    | Перекрестные ссылки в тексте, concepts.json, тема 5. |        |
| Ефименко К.И. | Gigachat API, темы 3-4.                                            |        |
| Нгуен Н.Х.А.  | Парсер wikidata, темы 6-7.                                          |        |
| Потапов Е.Д.  | Написание отчета, темы 1-2.                     |        |
| Серый Н.О.    | Написание отчета, концептуализация предметной области, структура онтологии.                    |        |

# 1. Работа с wikidata


## 1.1. Извлечение фрагментов знаний
Извлекали данные [отсюда](https://wikidata.org/) при помощи parse_wiki.py.
 
- Вход: принимает одно слово или фразу (концепцию). 
- Выход: краткое описание этой концепции.

### Алгоритм работы:

1. **Обработка входных данных**: скрипт берет переданный аргумент, нормализует его с помощью `pymorphy3`.
2. **Запрос к Wikidata**: получает QID по аргумент, извлекает его русскоязычное название из Wikidata.
3. **Запрос к Википедии**: запрашивает краткое описание из русскоязычной Википедии сначала по исходному названию, затем (если найдено) — по заголовку из Wikidata.
4. **Вывод результата**: печатает два описания — одно без использования Wikidata, второе (если найдено) с учетом заголовка оттуда.


## 1.2. Извлечение подграфа знаний
- https://wikidata.metaphacts.com/resource/app:Start


- Пример запроса:


```sparql
PREFIX wd: <http://www.wikidata.org/entity/>
PREFIX wdt: <http://www.wikidata.org/prop/direct/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX bd: <http://www.bigdata.com/rdf#>

SELECT ?phase ?phaseLabel ?subConcept ?subConceptLabel WHERE {
  # Задаём ключевые фазы. Обратите внимание, что для устранения избыточности,
  # схожие понятия (например, Детство и Зрелость) можно объединять под общим идентификатором.
  VALUES ?phase {
    wd:Q49257364    # Стадия младенчества
    wd:Q1340307     # Малыш
    wd:Q378915      # Детство/Зрелость (объединено для сокращения избыточности)
    wd:Q191089      # Старость
  }
  
  # Получаем связанные понятия (например, стадии, процессы, аспекты развития)
  ?phase (wdt:P279|wdt:P31)* ?subConcept.
  
  SERVICE wikibase:label { bd:serviceParam wikibase:language "ru". }
}

```



# 2. Стадии жизни

## 2.1. Концептуализация

- Диаграмма представляет концептуализацию, так как в ней отображены основные сущности, их свойства и связи между ними в рамках стадий жизни. При этом не задана строгая структура, как в онтологии.
- Более формальная онтология наблюдается на *wikidata* в виде связей "является частью" и т.п. 
- Для выбранных нами терминами *(там)* отсутствуют прямые концептуальные связи. На представленных скриншотах указаны наиболее релевантные и достаточные ассоциативные цепочки с сокращением избыточных связей.
- Переход от "ver_1.png" к diagram.md демонстирует снижение избыточности.

![ver_1](<src/ver_1.png>)
![diagram](<src/diagram.png>)
![photo-1](<src/1_newborn.png>)
![photo-2](<src/2_infancy.png>)
![photo-3](<src/3_early_childhood.png>)
![photo-4](<src/4_preschool_age.png>)
![photo-5](<src/5_school_age.png>)
![photo-6](<src/6_puberty.png>)
![photo-7](<src/7_youth.png>)
![photo-8](<src/8_maturity.png>)
![photo-9](<src/9_olg_age.png>)


# 3. Markdown-странички 

## 3.1. Gigachat API.

- Вход: Файл с запросами и API-ключ. 
- Выход: Ответы от Gigachat на каждый запрос, выведенные в консоль.

1. Инициализация:
    - Скрипт загружает API-ключ из переменной окружения GIGACHAT_API_KEY.
    - Создаётся объект Gigachat, который будет использоваться для взаимодействия с API.
    - С помощью argparse обрабатываются аргументы командной строки, чтобы получить путь к файлу с запросами.
        
2. Чтение запросов:
    - Функция read_prompts_from_file открывает указанный файл, читает его содержимое и разбивает текст на отдельные запросы по заданному разделителю (\n\n по умолчанию). Результат — список строк (prompts).
    
3. Обработка запросов:
    - Скрипт проходит по списку запросов в цикле.
    - Каждый запрос очищается от лишних пробелов (.strip()), отправляется в функцию send_to_gigachat, которая:
        - Формирует запрос к API Gigachat в виде сообщения с ролью user.    
        - Получает ответ от модели giga и возвращает его содержимое.
        
4. Вывод результата:
    - Для каждого запроса печатается сам запрос и полученный ответ.    
    - Между запросами добавляется пауза в 0.5 секунды (time.sleep(0.5)), чтобы избежать перегрузки API или превышения лимита запросов.

## 3.2. Используемый промпт

```md

**Создай статью в формате Markdown на тему «[ТЕРМИН]», которая будет понятна и интересна 10-летнему ребенку. В статье используйте простые слова, примеры из повседневной жизни, а также добавьте эмодзи и подзаголовки, чтобы сделать текст ярким и наглядным. Включите следующие разделы:**

1. **Введение**: Объяснение, что такое «[ТЕРМИН]», с простыми примерами и понятиями.
2. **Почему это важно**: Объяснение, почему понимание и знание «[ТЕРМИН]» важно для жизни.
3. **Примеры из жизни**: Примеры, как «[ТЕРМИН]» встречается в повседневной жизни (с использованием доступных аналогий и примеров).
4. **Что делают люди с этим**: Объяснение, как люди занимаются «[ТЕРМИН]» (например, профессии, занятия, активность).
5. **Как развиваться в этой области**: Советы, как можно изучать или развиваться в области «[ТЕРМИН]».
6. **Что делать, если сталкиваешься с трудностями**: Какие могут возникнуть сложности, и как их можно преодолеть.
7. **Заключение**: Позитивное заключение, которое мотивирует и вдохновляет.

```


## 3.3. Расстановка ссылок в тексте

### Вход
- Путь к директории с файлами Markdown (.md) — переменная `PATH` (строка, например, `'pages'`).
- Опциональный файл `names.md` с паттернами (список строк); если отсутствует, паттерны берутся из имен файлов в директории.
### Выход
- Обновленные файлы Markdown в директории `PATH` с добавленными ссылками в формате `[[текст|паттерн]]`, где текст сохраняет исходные падежи, а паттерн указывает на связанное имя или страницу.
### Алгоритм
1. **Сбор данных**: Функция `get_pages` читает все .md файлы из директории `PATH`, создавая словарь `{имя_файла: текст}`.
2. **Определение паттернов**: Если файл `names.md` существует, паттерны читаются из него; иначе `get_names` извлекает имена из ключей словаря файлов.
3. **Нормализация текста и паттернов**: В `add_links` текст разбивается на слова, каждое нормализуется через `morph.parse(word)[0].normal_form` (именительный падеж, единственное число) с помощью `pymorphy3`; паттерны нормализуются аналогично.
4. **Поиск совпадений**: Алгоритм Ахо-Корасика в `build_automaton` и `search_text` ищет позиции нормализованных паттернов в нормализованном тексте, возвращая словарь `{паттерн: [оригинальный_паттерн, позиции]}`.
5. **Добавление ссылок**: Для каждой найденной позиции в исходном тексте (сохраняя оригинальные слова с падежами) вставляется разметка `[[текст|паттерн]]`, где `текст` — фрагмент исходного текста, а `паттерн` — связанное имя; результат собирается в новый словарь `{имя_файла: обновленный_текст}`.
6. **Запись результата**: Функция `update_pages` переписывает файлы в директории `PATH` с обновленным содержимым из нового словаря.


## 4. Выводы

Логику полученной структуры иерархических и горизонтальных связей концептуализации можно обосновать в 5 предложениях:
1. Системный анализ через причинно-следственные цепочки
2. Соответствие эмпирическим данным
3. Формальная проверка на непротиворечивость
4. Семантическая связность через онтологию
5. Тестирование альтернативных сценариев

В качестве направления улучшения работы видим формализацию структуры онтологии.

Важно отметить и философские аспекты при работе с ИИ, такие как достоверность полученной информации и необходимость валидации полученных ответов практическим опытом/аппеляцией к доверенному источнику информации. 